{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac7d9d8",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "\n",
    "\n",
    "# Merton Jump Diffusion model (MJD) parameters:\n",
    "# mu - Drift\n",
    "# sigma - Volatility\n",
    "# lambda - Jump intensity (average number of jumps per year)\n",
    "# gamma - Mean of the jump size (log-normal jump)\n",
    "# delta - Standard deviation of the jump size\n",
    "\n",
    "mjd_par = np.array(\n",
    "    [[0.05, 0.2, 5, 0.02, 0.0125], # (mu,sigma, lambda, gamma, delta) bull-regime\n",
    "    [-0.05, 0.4, 10, -0.04, 0.1]]) # (mu,sigma, lambda, gamma, delta) bear-regime\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f38bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d478b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjd(S0, mu, sigma, lam, gamma, delta, n):\n",
    "    \"\"\"\n",
    "    Simulates a Merton Jump Diffusion process (MJD).\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift\n",
    "    sigma (float): Volatility\n",
    "    lambda_ (float): Jump intensity (average number of jumps per year)\n",
    "    gamma (float): Mean of the jump size (log-normal jump)\n",
    "    delta (float): Standard deviation of the jump size\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize arrays to store the simulated path\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    \n",
    "    # Simulate Brownian motion for the continuous part\n",
    "    dW = np.random.normal(0, np.sqrt(dt), n-1)\n",
    "    \n",
    "    # Simulate Poisson process for the jump part\n",
    "    dN = np.random.poisson(lam * dt, n-1)\n",
    "    \n",
    "    # Simulate jump sizes (log-normal distribution for jumps)\n",
    "    J = np.exp(np.random.normal(gamma, delta, n-1))\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        # Continuous part (Brownian motion)\n",
    "        S[i] = S[i-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * dW[i-1])\n",
    "        \n",
    "        # Jump part (if a jump occurs, dN[i-1] will be 1)\n",
    "        if dN[i-1] > 0:\n",
    "            S[i] *= J[i-1]  # Apply jump (multiply by the jump size)\n",
    "        \n",
    "    return S\n",
    "\n",
    "def mjd_path(N_prime, C, t):\n",
    "    '''\n",
    "    It simulates the entire path of a MJD with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 30\n",
    "np.random.seed(seed_path)\n",
    "\n",
    "# relevant time series\n",
    "prices = mjd_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "# it was just a check for the seed...\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Merton Jump Diffusion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a65a93",
   "metadata": {},
   "source": [
    "# M k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a89aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKMeans:\n",
    "    \n",
    "    def __init__(self, max_iter, tol, n_clusters=2, random_state=None):\n",
    "        \n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Initialize cluster centers\n",
    "        indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.cluster_centers_ = X[indices]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            # Compute distances and assign clusters\n",
    "            distances = pairwise_distances(X, self.cluster_centers_, metric='euclidean')\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Compute new cluster centers\n",
    "            new_centers = np.array([np.mean(X[labels == j] ,axis=0) for j in range(self.n_clusters)])\n",
    "            \n",
    "            # Check for convergence\n",
    "            loss = 0\n",
    "            for j in range(self.n_clusters):\n",
    "                loss = loss + np.linalg.norm(self.cluster_centers_[j] - new_centers[j])\n",
    "                \n",
    "            if loss < self.tol:\n",
    "                break\n",
    "\n",
    "            self.cluster_centers_ = new_centers\n",
    "\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = pairwise_distances(X, self.cluster_centers_, metric=euclidean_distance)\n",
    "        return np.argmin(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costruction of a suitable dataset\n",
    "\n",
    "# from each empiracal cdf we take the firsts q moments (a vector of dim. q for each empirical cdf)\n",
    "q = 4\n",
    "\n",
    "# Function to compute the k-th raw moment along a specified axis\n",
    "def raw_moment_nd(values, k, axis=None):\n",
    "    return np.mean(values**k, axis=axis)\n",
    "\n",
    "\n",
    "# compute raw moments along the specified axis (axis=None computes the raw moments over the entire array)\n",
    "X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "# print the standardized data\n",
    "print(np.mean(standardized_X_moments, axis=0))\n",
    "print(np.std(standardized_X_moments, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b56f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the  MK-means\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "seed_clustering = 1\n",
    "\n",
    "mkmeans = MKMeans(max_iter=max_iter, tol=tol, random_state=seed_clustering)\n",
    "mkmeans.fit(standardized_X_moments)\n",
    "\n",
    "# centroids in the real space\n",
    "centroids = scaler.inverse_transform(mkmeans.cluster_centers_) \n",
    "\n",
    "# off-regime-> higher number of elements\n",
    "off_regime_index = 0 \n",
    "# on-regime-> lower number of elements\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (mkmeans.labels_ == 0).sum() < (mkmeans.labels_ == 1).sum():\n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "    \n",
    "    \n",
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "\n",
    "# scatter plot of centroids\n",
    "\n",
    "plt.scatter(np.sqrt(centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2),\n",
    "            centroids[off_regime_index][0],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(np.sqrt(centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2),\n",
    "            centroids[on_regime_index][0],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'M k-means with p={q}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{q}_M_means_{seed_clustering}_h_{h_1}_{h_2}_MJD_{seed_path}_ite_{max_iter}_tol_{tol}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d414c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_and_kurtosis(M):\n",
    "    \"\"\"\n",
    "    Calculate skewness and excess kurtosis using raw moments.\n",
    "    \n",
    "    Parameters:\n",
    "    M1: First raw moment (mean)\n",
    "    M2: Second raw moment (variance-related)\n",
    "    M3: Third raw moment\n",
    "    M4: Fourth raw moment\n",
    "    \n",
    "    Returns:\n",
    "    skewness, excess kurtosis\n",
    "    \"\"\"\n",
    "    M1 = M[0]\n",
    "    M2 = M[1]\n",
    "    M3 = M[2]\n",
    "    M4 = M[3]\n",
    "    \n",
    "    # Calculate variance (second central moment, which is just variance)\n",
    "    mu2 = M2 - M1**2\n",
    "\n",
    "    # Calculate third central moment\n",
    "    mu3 = M3 - 3 * M1 * M2 + 2 * M1**3\n",
    "\n",
    "    # Calculate fourth central moment\n",
    "    mu4 = M4 - 4 * M1 * M3 + 6 * M1**2 * M2 - 3 * M1**4\n",
    "\n",
    "    # Calculate skewness\n",
    "    skewness = mu3 / mu2**(3/2)\n",
    "\n",
    "    # Calculate excess kurtosis (subtract 3 from kurtosis)\n",
    "    excess_kurtosis = (mu4 / mu2**2) - 3\n",
    "\n",
    "    return skewness, excess_kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "# scatter plot of centroids\n",
    "skewness_0, excess_kurtosis_0 = skewness_and_kurtosis(centroids[off_regime_index])\n",
    "plt.scatter(skewness_0,\n",
    "            excess_kurtosis_0,\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "\n",
    "skewness_1, excess_kurtosis_1 = skewness_and_kurtosis(centroids[on_regime_index])\n",
    "plt.scatter(skewness_1,\n",
    "            excess_kurtosis_1,\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'M k-means with p={q}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{q}_M_means_{seed_clustering}_h_{h_1}_{h_2}_MJD_{seed_path}_ite_{max_iter}_tol_{tol}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5545dc0",
   "metadata": {},
   "source": [
    "# Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c993134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc999a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(mkmeans, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "dec = 4\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, dec)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, dec)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, dec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2405ac",
   "metadata": {},
   "source": [
    "## log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important function to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "        \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a608c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "\n",
    "\n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b360e62",
   "metadata": {},
   "source": [
    "## price path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab15f8",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99939d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulas from the theory\n",
    "theo_mean_bull = (mjd_par[0][0] - (mjd_par[0][1]**2)/2 + mjd_par[0][3]*mjd_par[0][2])*dt\n",
    "theo_mean_bear = (mjd_par[1][0] - (mjd_par[1][1]**2)/2 + mjd_par[1][3]*mjd_par[1][2])*dt\n",
    "\n",
    "theo_variance_bull = (mjd_par[0][1]**2 + mjd_par[0][2]*(mjd_par[0][4]**2 + mjd_par[0][3]**2))*dt\n",
    "theo_variance_bear = (mjd_par[1][1]**2 + mjd_par[1][2]*(mjd_par[1][4]**2 + mjd_par[1][3]**2))*dt\n",
    "\n",
    "theo_std_bull = np.sqrt(theo_variance_bull)\n",
    "theo_std_bear = np.sqrt(theo_variance_bear)\n",
    "\n",
    "# print values\n",
    "print(f\"mean bull = {theo_mean_bull}\")\n",
    "print(f\"mean centroid 0 = {centroids[off_regime_index][0]}\")\n",
    "\n",
    "print(f\"\\nvariance bull = {theo_variance_bull}\")\n",
    "print(f\"variance centroid 0 = {centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2}\")\n",
    "\n",
    "\n",
    "print(f\"\\nmean bear = {theo_mean_bear}\")\n",
    "print(f\"mean centroid 1 = {centroids[on_regime_index][0]}\")\n",
    "\n",
    "print(f\"\\nvariance bear = {theo_variance_bear}\")\n",
    "print(f\"variance centroid 1 = {centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0439047",
   "metadata": {},
   "source": [
    "## histogram for the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1726444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.mean(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b', density=True) \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_mean_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_mean_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=centroids[off_regime_index][0], color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=centroids[on_regime_index][0], color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "# plt.title('Distribution')\n",
    "plt.xlabel('Î¼')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93214b",
   "metadata": {},
   "source": [
    "## histogram for the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad73ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.std(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b', density=True)  \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_std_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_std_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.sqrt(centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2), color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=np.sqrt(centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2), color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(f'$\\sigma$')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea6f94",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d285bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, q, max_iter, tol, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs): \n",
    "        \n",
    "        # data preparation\n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(mjd_path(N_prime, price_labels, t)))\n",
    "        # start timing\n",
    "        start = time.time()\n",
    "        lift_matrix = lift_function(h_1, h_2, log_returns, M)[0]\n",
    "        \n",
    "        X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "        # initialize the StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        # fit and transform the data\n",
    "        standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "        # clustering\n",
    "        mkmeans = MKMeans(max_iter=max_iter, tol=tol)\n",
    "        mkmeans.fit(standardized_X_moments)\n",
    "\n",
    "        # centroids in the real space\n",
    "        centroids = scaler.inverse_transform(mkmeans.cluster_centers_) \n",
    "\n",
    "        # off-regime-> higher number of elements\n",
    "        off_regime_index = 0 \n",
    "        # on-regime-> lower number of elements\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (mkmeans.labels_ == 0).sum() < (mkmeans.labels_ == 1).sum():\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "            \n",
    "        # counter    \n",
    "        r_counter = opt_counter(mkmeans, len(log_returns), M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Q = 4\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "n_runs = 50\n",
    "\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, Q, max_iter, tol, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(f'numerical_results/{Q}_M_means_h_{h_1}_{h_2}_MJD_n_{n_runs}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
