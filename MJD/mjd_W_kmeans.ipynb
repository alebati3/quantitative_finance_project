{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8deea7b6",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbc7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "\n",
    "\n",
    "# Merton Jump Diffusion model (MJD) parameters:\n",
    "# mu - Drift\n",
    "# sigma - Volatility\n",
    "# lambda - Jump intensity (average number of jumps per year)\n",
    "# gamma - Mean of the jump size (log-normal jump)\n",
    "# delta - Standard deviation of the jump size\n",
    "\n",
    "mjd_par = np.array(\n",
    "    [[0.05, 0.2, 5, 0.02, 0.0125], # (mu,sigma, lambda, gamma, delta) bull-regime\n",
    "    [-0.05, 0.4, 10, -0.04, 0.1]]) # (mu,sigma, lambda, gamma, delta) bear-regime\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beca9a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mjd(S0, mu, sigma, lam, gamma, delta, n):\n",
    "    \"\"\"\n",
    "    Simulates a Merton Jump Diffusion process (MJD).\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift\n",
    "    sigma (float): Volatility\n",
    "    lambda_ (float): Jump intensity (average number of jumps per year)\n",
    "    gamma (float): Mean of the jump size (log-normal jump)\n",
    "    delta (float): Standard deviation of the jump size\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize arrays to store the simulated path\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    \n",
    "    # Simulate Brownian motion for the continuous part\n",
    "    dW = np.random.normal(0, np.sqrt(dt), n-1)\n",
    "    \n",
    "    # Simulate Poisson process for the jump part\n",
    "    dN = np.random.poisson(lam * dt, n-1)\n",
    "    \n",
    "    # Simulate jump sizes (log-normal distribution for jumps)\n",
    "    J = np.exp(np.random.normal(gamma, delta, n-1))\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        # Continuous part (Brownian motion)\n",
    "        S[i] = S[i-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * dW[i-1])\n",
    "        \n",
    "        # Jump part (if a jump occurs, dN[i-1] will be 1)\n",
    "        if dN[i-1] > 0:\n",
    "            S[i] *= J[i-1]  # Apply jump (multiply by the jump size)\n",
    "        \n",
    "    return S\n",
    "\n",
    "def mjd_path(N_prime, C, t):\n",
    "    '''\n",
    "    It simulates the entire path of a MJD with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 20\n",
    "np.random.seed(20)\n",
    "\n",
    "# relevant time series\n",
    "prices = mjd_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "# it was just a check for the seed...\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Merton Jump Diffusion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8110af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "X_wasserstein = sorted_lift_matrix\n",
    "\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcc9c5",
   "metadata": {},
   "source": [
    "## WK-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea249297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WassersteinKMeans:\n",
    "    def __init__(self, p, max_iter, tol, n_clusters = 2, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.p = p\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Obs: the rows of X are already ordered\n",
    "        np.random.seed(self.random_state)\n",
    "        # n_atoms represents the number of atoms for the empirical cdf\n",
    "        n_samples, n_atoms = X.shape\n",
    "\n",
    "        # Initialize cluster centers\n",
    "        indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.cluster_centers_ = X[indices]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            # Compute distances and assign clusters\n",
    "            distances = pairwise_distances(X, self.cluster_centers_, metric='minkowski') / (n_atoms**(1/self.p))\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Compute new cluster centers\n",
    "            new_centers = np.array([np.median(X[labels == j] ,axis=0) for j in range(self.n_clusters)])\n",
    "            # just to be sure that the new centroids are ordered sequences\n",
    "            new_centers.sort()\n",
    "            \n",
    "            # Check for convergence\n",
    "            loss = 0\n",
    "            for j in range(self.n_clusters):\n",
    "                \n",
    "                loss = loss + minkowski(self.cluster_centers_[j], new_centers[j], p=self.p) / (n_atoms**(1/self.p))\n",
    "            if loss < self.tol:\n",
    "                break\n",
    "\n",
    "            self.cluster_centers_ = new_centers\n",
    "\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = pairwise_distances(X, self.cluster_centers_, metric='minkowski') / (X.shape[1]**(1/self.p))\n",
    "        return np.argmin(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clustering parameters\n",
    "P = 2\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "seed_clustering = 1\n",
    "\n",
    "wkmeans = WassersteinKMeans(p=P, max_iter=max_iter, tol=tol, random_state=seed_clustering)\n",
    "# Fit the Wasserstein KMeans\n",
    "wkmeans.fit(X_wasserstein)\n",
    "\n",
    "# off-regime-> cluster with a higher numeber of elements\n",
    "off_regime_index = 0 \n",
    "# on-regime-> cluster with a lower numeber of elements\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (wkmeans.labels_ == 0).sum() < (wkmeans.labels_ == 1).sum():\n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    np.std(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    np.std(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "# scatter plot of centroids\n",
    "plt.scatter(np.std(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(np.std(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'W k-means with p={P}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{P}_W_means_{seed_clustering}_h_{h_1}_{h_2}_MJD_{seed_path}_ite_{max_iter}_tol_{tol}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c18f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    skew(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    skew(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "# scatter plot of centroids\n",
    "plt.scatter(skew(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            kurtosis(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(skew(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            kurtosis(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'W k-means with p={P}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{P}_W_means_{seed_clustering}_h_{h_1}_{h_2}_MJD_{seed_path}_ite_{max_iter}_tol_{tol}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d420a64",
   "metadata": {},
   "source": [
    "## Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310916d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(wkmeans, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, 3)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, 3)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c726a73",
   "metadata": {},
   "source": [
    "## log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two important functions to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcba6f",
   "metadata": {},
   "source": [
    "## price path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b466ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7917938d",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulas from the theory\n",
    "theo_mean_bull = (mjd_par[0][0] - (mjd_par[0][1]**2)/2 + mjd_par[0][3]*mjd_par[0][2])*dt\n",
    "theo_mean_bear = (mjd_par[1][0] - (mjd_par[1][1]**2)/2 + mjd_par[1][3]*mjd_par[1][2])*dt\n",
    "\n",
    "theo_variance_bull = (mjd_par[0][1]**2 + mjd_par[0][2]*(mjd_par[0][4]**2 + mjd_par[0][3]**2))*dt\n",
    "theo_variance_bear = (mjd_par[1][1]**2 + mjd_par[1][2]*(mjd_par[1][4]**2 + mjd_par[1][3]**2))*dt\n",
    "\n",
    "theo_std_bull = np.sqrt(theo_variance_bull)\n",
    "theo_std_bear = np.sqrt(theo_variance_bear)\n",
    "\n",
    "# print values\n",
    "print(f\"mean bull = {theo_mean_bull}\")\n",
    "print(f\"mean centroid 0 = {np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index]}\")\n",
    "\n",
    "print(f\"\\nvariance bull = {theo_variance_bull}\")\n",
    "print(f\"variance centroid 0 = {np.var(wkmeans.cluster_centers_, axis=1)[off_regime_index]}\")\n",
    "\n",
    "\n",
    "print(f\"\\nmean bear = {theo_mean_bear}\")\n",
    "print(f\"mean centroid 1 = {np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index]}\")\n",
    "\n",
    "print(f\"\\nvariance bear = {theo_variance_bear}\")\n",
    "print(f\"variance centroid 1 = {np.var(wkmeans.cluster_centers_, axis=1)[on_regime_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242e9b5",
   "metadata": {},
   "source": [
    "## histogram of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd87b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.mean(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b') \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_mean_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_mean_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index], color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index], color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Distribution')\n",
    "plt.xlabel('μ')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39658c",
   "metadata": {},
   "source": [
    "## histogram of the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07387b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.std(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b')  \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_std_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_std_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.std(wkmeans.cluster_centers_, axis=1)[off_regime_index], color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=np.std(wkmeans.cluster_centers_, axis=1)[on_regime_index], color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(f'$\\sigma$')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38cb3f",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, p, max_iter, tol, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs): \n",
    "        # data preparation\n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(mjd_path(N_prime, price_labels, t)))\n",
    "        X_wasserstein = lift_function(h_1, h_2, log_returns, M)[1]\n",
    "        \n",
    "        # clustering\n",
    "        start = time.time()\n",
    "        \n",
    "        wkmeans = WassersteinKMeans(p=p, max_iter=max_iter, tol=tol)\n",
    "        wkmeans.fit(X_wasserstein)\n",
    "        \n",
    "        # off-regime-> cluster with a higher number of elements\n",
    "        off_regime_index = 0 \n",
    "        # on-regime-> cluster with a lower number of elements\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (wkmeans.labels_ == 0).sum() < (wkmeans.labels_ == 1).sum():\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "\n",
    "            \n",
    "        # counter   \n",
    "        r_counter = opt_counter(wkmeans, N_prime, M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c40103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clustering validation parameters\n",
    "P = 1\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "n_runs = 50\n",
    "\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, P, max_iter, tol, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "df.to_csv(f'numerical_results/{P}_W_means_h_{h_1}_{h_2}_MJD_n_{n_runs}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
