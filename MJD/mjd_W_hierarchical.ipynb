{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6fbba1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "\n",
    "\n",
    "# Merton Jump Diffusion model (MJD) parameters:\n",
    "# mu - Drift\n",
    "# sigma - Volatility\n",
    "# lambda - Jump intensity (average number of jumps per year)\n",
    "# gamma - Mean of the jump size (log-normal jump)\n",
    "# delta - Standard deviation of the jump size\n",
    "\n",
    "mjd_par = np.array(\n",
    "    [[0.05, 0.2, 5, 0.02, 0.0125], # (mu,sigma, lambda, gamma, delta) bull-regime\n",
    "    [-0.05, 0.4, 10, -0.04, 0.1]]) # (mu,sigma, lambda, gamma, delta) bear-regime\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ce543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjd(S0, mu, sigma, lam, gamma, delta, n):\n",
    "    \"\"\"\n",
    "    Simulates a Merton Jump Diffusion process (MJD).\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift\n",
    "    sigma (float): Volatility\n",
    "    lambda_ (float): Jump intensity (average number of jumps per year)\n",
    "    gamma (float): Mean of the jump size (log-normal jump)\n",
    "    delta (float): Standard deviation of the jump size\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize arrays to store the simulated path\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    \n",
    "    # Simulate Brownian motion for the continuous part\n",
    "    dW = np.random.normal(0, np.sqrt(dt), n-1)\n",
    "    \n",
    "    # Simulate Poisson process for the jump part\n",
    "    dN = np.random.poisson(lam * dt, n-1)\n",
    "    \n",
    "    # Simulate jump sizes (log-normal distribution for jumps)\n",
    "    J = np.exp(np.random.normal(gamma, delta, n-1))\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        # Continuous part (Brownian motion)\n",
    "        S[i] = S[i-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * dW[i-1])\n",
    "        \n",
    "        # Jump part (if a jump occurs, dN[i-1] will be 1)\n",
    "        if dN[i-1] > 0:\n",
    "            S[i] *= J[i-1]  # Apply jump (multiply by the jump size)\n",
    "        \n",
    "    return S\n",
    "\n",
    "def mjd_path(N_prime, C, t):\n",
    "    '''\n",
    "    It simulates the entire path of a MJD with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = mjd(s_0, mjd_par[C[k]][0], mjd_par[C[k]][1], mjd_par[C[k]][2], mjd_par[C[k]][3], mjd_par[C[k]][4], len(t[start_index : stop_index + 1]))\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 15\n",
    "np.random.seed(seed_path)\n",
    "\n",
    "# relevant time series\n",
    "prices = mjd_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "# it was just a check for the seed...\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Merton Jump Diffusion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "X_wasserstein = sorted_lift_matrix\n",
    "\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ce33e",
   "metadata": {},
   "source": [
    "# W Hierarchical (agglomerative) clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca086ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "P = 2\n",
    "distance_matrix = pairwise_distances(sorted_lift_matrix, metric='minkowski', p=P) / (sorted_lift_matrix.shape[1]**(1/P))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689bdb20",
   "metadata": {},
   "source": [
    "kinds of linkage:\n",
    "\n",
    "‘average’ uses the average of the distances of each observation of the two sets.\n",
    "\n",
    "‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.\n",
    "\n",
    "‘single’ uses the minimum of the distances between all observations of the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653637ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Agglomerative Clustering with the precomputed distance matrix\n",
    "linkage = 'complete'\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage=linkage)\n",
    "clustering.fit_predict(distance_matrix)\n",
    "\n",
    "# off-regime->lower variance\n",
    "off_regime_index = 0 \n",
    "# on-regime->higher variance\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (clustering.labels_ == 1).sum() > (clustering.labels_ == 0).sum():\n",
    "    \n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "point_size = 5\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.5, s=point_size, label='predicted off regime')\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[clustering.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[clustering.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=1, s=point_size, label='predicted on regime')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'W-Hierarchical {linkage} linkage with p={P}')\n",
    "plt.legend()\n",
    "# PAY ATTENTION\n",
    "# plt.savefig(f'figures/{P}_W_Hierarchical_{linkage}_h_{h_1}_{h_2}_MJD_{seed_path}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f07f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of empirical cdf\n",
    "point_size = 5\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='b', alpha=0.5, s=point_size, label='predicted off regime')\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[clustering.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[clustering.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='r', alpha=1, s=point_size, label='predicted on regime')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'W-Hierarchical {linkage} linkage with p={P}')\n",
    "plt.legend()\n",
    "# PAY ATTENTION\n",
    "# plt.savefig(f'figures/{P}_W_Hierarchical_{linkage}_h_{h_1}_{h_2}_MJD_{seed_path}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34990fb",
   "metadata": {},
   "source": [
    "# Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f16264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(clustering, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "dec = 4\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, dec)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, dec)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, dec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897baa2",
   "metadata": {},
   "source": [
    "## log-return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd51d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two important functions to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d76387",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a0510",
   "metadata": {},
   "source": [
    "## price path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da693a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebd2c5",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49eb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, p, linkage, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs):  \n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(mjd_path(N_prime, price_labels, t)))\n",
    "        ##\n",
    "        start = time.time()\n",
    "        sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)[1]\n",
    "        \n",
    "        distance_matrix = pairwise_distances(sorted_lift_matrix, metric='minkowski', p=p) / (sorted_lift_matrix.shape[1]**(1/p))\n",
    "        \n",
    "        ##### clustering\n",
    "        \n",
    "        clustering = AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage=linkage)\n",
    "        clustering.fit_predict(distance_matrix)\n",
    "\n",
    "        # off-regime\n",
    "        off_regime_index = 0 \n",
    "        # on-regime\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (clustering.labels_ == 1).sum() > (clustering.labels_ == 0).sum():\n",
    "\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "        \n",
    "            \n",
    "        # counter   \n",
    "        r_counter = opt_counter(clustering, N_prime, M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_runs = 50\n",
    "Linkage = 'complete'\n",
    "P = 2\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, P, Linkage, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd888382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "df.to_csv(f'numerical_results/{P}_W_Hierarchical_{Linkage}_h_{h_1}_{h_2}_MJD_n_{n_runs}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0bbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
