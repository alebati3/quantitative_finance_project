{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce0faec",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "# GBM parameters\n",
    "gbm_par = np.array(\n",
    "    [[0.02, 0.2], #mu,sigma *bull-regime*\n",
    "    [-0.02, 0.3]]) #mu,sigma *bear-regime*\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70576f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbm(S0, mu, sigma, n):\n",
    "    \"\"\"\n",
    "    Simulates a Geometric Brownian Motion (GBM) by using the analytical solution.\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift coefficient\n",
    "    sigma (float): Volatility coefficient\n",
    "    T (float): Time horizon\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    t = np.arange(1, n) * dt\n",
    "    W = np.random.standard_normal(size=n-1) \n",
    "    W = np.cumsum(W) * np.sqrt(dt) # cumulative sum to simulate the Brownian motion\n",
    "    X = (mu - 0.5 * sigma**2) * t + sigma * W\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    S[1:] = S0 * np.exp(X)\n",
    "    return S\n",
    "\n",
    "def gbm_path(N_prime, C, t):\n",
    "    '''\n",
    "    It simulates the entire path of a GBM with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]))\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]))\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 15\n",
    "np.random.seed(seed_path)\n",
    "\n",
    "# relevant time series\n",
    "prices = gbm_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Geometric Brownian Motion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee25f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "X_wasserstein = sorted_lift_matrix\n",
    "\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e0af6",
   "metadata": {},
   "source": [
    "# W k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c86804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WassersteinKMeans:\n",
    "    def __init__(self, p, max_iter, tol, n_clusters = 2, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.p = p\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Obs: the rows of X are already ordered\n",
    "        np.random.seed(self.random_state)\n",
    "        # n_atoms represents the number of atoms for the empirical cdf\n",
    "        n_samples, n_atoms = X.shape\n",
    "\n",
    "        # Initialize cluster centers\n",
    "        indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.cluster_centers_ = X[indices]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            # Compute distances and assign clusters\n",
    "            distances = pairwise_distances(X, self.cluster_centers_, metric='minkowski') / (n_atoms**(1/self.p))\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Compute new cluster centers\n",
    "            new_centers = np.array([np.median(X[labels == j] ,axis=0) for j in range(self.n_clusters)])\n",
    "            # just to be sure that the new centroids are ordered sequences\n",
    "            new_centers.sort()\n",
    "            \n",
    "            # Check for convergence\n",
    "            loss = 0\n",
    "            for j in range(self.n_clusters):\n",
    "                \n",
    "                loss = loss + minkowski(self.cluster_centers_[j], new_centers[j], p=self.p) / (n_atoms**(1/self.p))\n",
    "            if loss < self.tol:\n",
    "                break\n",
    "\n",
    "            self.cluster_centers_ = new_centers\n",
    "\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = pairwise_distances(X, self.cluster_centers_, metric='minkowski') / (X.shape[1]**(1/self.p))\n",
    "        return np.argmin(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca348ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clustering parameters\n",
    "P = 1\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "seed_clustering = 10\n",
    "\n",
    "wkmeans = WassersteinKMeans(p=P, max_iter=max_iter, tol=tol, random_state=seed_clustering)\n",
    "# Fit the Wasserstein KMeans\n",
    "wkmeans.fit(X_wasserstein)\n",
    "\n",
    "# off-regime-> cluster with a higher numeber of elements\n",
    "off_regime_index = 0 \n",
    "# on-regime-> cluster with a lower numeber of elements\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (wkmeans.labels_ == 0).sum() < (wkmeans.labels_ == 1).sum():\n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "plt.figure(figsize=(10, 6))\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    np.std(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.5, s=point_size)\n",
    "plt.scatter(\n",
    "    np.std(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.5, s=point_size)\n",
    "# scatter plot of centroids\n",
    "plt.scatter(np.std(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(np.std(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'W k-means with p={P}')\n",
    "plt.legend()\n",
    "# PAY ATTENTION\n",
    "# plt.savefig(f'figures/{P}_W_means_{seed_clustering}_h_{h_1}_{h_2}_GBM_{seed_path}_ite_{max_iter}_tol_{tol}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f39503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of empirical cdf\n",
    "plt.figure(figsize=(10, 6))\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    skew(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(X_wasserstein[wkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.5, s=point_size)\n",
    "plt.scatter(\n",
    "    skew(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(X_wasserstein[wkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.5, s=point_size)\n",
    "# scatter plot of centroids\n",
    "plt.scatter(skew(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            kurtosis(wkmeans.cluster_centers_, axis=1)[off_regime_index],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(skew(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            kurtosis(wkmeans.cluster_centers_, axis=1)[on_regime_index],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'W k-means with p={P}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{P}_W_means_{seed_clustering}_h_{h_1}_{h_2}_GBM_{seed_path}_ite_{max_iter}_tol_{tol}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6178e",
   "metadata": {},
   "source": [
    "# Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe68c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter = np.zeros((len(log_returns), 2))\n",
    "\n",
    "for k in range(len(log_returns)):\n",
    "    for j in range(M):\n",
    "\n",
    "        if k - (h_1 - h_2) * j >= 0 and k - (h_1 - h_2) * j <= h_1:\n",
    "\n",
    "            if wkmeans.labels_[j] == 0:\n",
    "                r_counter[k][0] += 1\n",
    "            else:\n",
    "                r_counter[k][1] += 1\n",
    "                \n",
    "                \n",
    "s_counter = np.zeros((len(prices), 2))\n",
    "\n",
    "for j in range(len(prices)):\n",
    "\n",
    "    if j == 0 :\n",
    "        s_counter[j][0] = r_counter[j][0]\n",
    "        s_counter[j][1] = r_counter[j][1]\n",
    "\n",
    "    elif j == (len(prices) - 1) :\n",
    "        s_counter[j][0] = r_counter[j-1][0]\n",
    "        s_counter[j][1] = r_counter[j-1][1]\n",
    "\n",
    "    else:\n",
    "        s_counter[j][0] = r_counter[j][0] + r_counter[j-1][0]\n",
    "        s_counter[j][1] = r_counter[j][1] + r_counter[j-1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization of the previous code by using ChatGPT\n",
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c012d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(wkmeans, len(log_returns), M, h_1, h_2)\n",
    "# # check\n",
    "# a, b = opt(wkmeans, len(prices), M, h_1, h_2)\n",
    "# print((a == r_counter).all())\n",
    "# print((b == s_counter).all())\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, 3)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, 3)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1abbce",
   "metadata": {},
   "source": [
    "# dependence by the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: run again if you change somenthing in Data preparation !!!\n",
    "\n",
    "def wk_means_function(p, max_iter, tol, random_seed):\n",
    "\n",
    "    wkmeans = WassersteinKMeans(p=p, max_iter=max_iter, tol=tol, random_state=random_seed)\n",
    "    wkmeans.fit(X_wasserstein)\n",
    "\n",
    "    # off-regime-> cluster with a higher number of elements\n",
    "    off_regime_index = 0 \n",
    "    # on-regime-> cluster with a lower number of elements\n",
    "    on_regime_index = 1 \n",
    "    # check regime\n",
    "    if (wkmeans.labels_ == 0).sum() < (wkmeans.labels_ == 1).sum():\n",
    "        off_regime_index = 1\n",
    "        on_regime_index = 0\n",
    "\n",
    "    r_counter = opt_counter(wkmeans, len(log_returns), M, h_1, h_2)[0]\n",
    "\n",
    "    # regime-off accuracy score (ROFS)\n",
    "    ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "    # regime-off accuracy score (ROFS)\n",
    "    RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "    # total accuracy (TA)\n",
    "    TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "    \n",
    "    return ROFS, RONS, TA\n",
    "\n",
    "def convert_seconds(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    remaining_seconds = seconds % 60\n",
    "    return f\"{minutes} min {int(remaining_seconds)} seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering parameters\n",
    "P = 1\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "\n",
    "n_trials = 50\n",
    "\n",
    "rofs = np.zeros(n_trials)\n",
    "rons = np.zeros(n_trials)\n",
    "ta = np.zeros(n_trials)\n",
    "iteration_times = np.zeros(n_trials)\n",
    "\n",
    "start_time_tot = time.time()\n",
    "for i in range(n_trials):\n",
    "    # start\n",
    "    start_time = time.time()\n",
    "    # clustering\n",
    "    rofs[i], rons[i], ta[i] = wk_means_function(p=P, max_iter=max_iter, tol=tol, random_seed=i+1)\n",
    "    # end\n",
    "    end_time = time.time()\n",
    "    # save data\n",
    "    iteration_times[i] = end_time - start_time\n",
    "end_time_tot = time.time()\n",
    "\n",
    "input_seconds = float(end_time_tot - start_time_tot)\n",
    "print(f'time to complete all the iterations = {convert_seconds(input_seconds)}')\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(f'numerical_results_stability/{P}_W_means_h_{h_1}_{h_2}_GBM_{seed_path}_n_{n_trials}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results_stability/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "n_trials = len(ta)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21cec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_bins = int(np.sqrt(n_trials))\n",
    "# nn_bins = n_trials\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(rofs, bins=nn_bins, density=True)\n",
    "plt.xlabel('ROFS')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.hist(rons, bins=nn_bins, density=True)\n",
    "plt.xlabel('RONS')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.hist(ta, bins=nn_bins, density=True)\n",
    "plt.xlabel('TA')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.hist(iteration_times, bins=nn_bins, density=True)\n",
    "plt.xlabel('RUN TIME (seconds)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640b43a",
   "metadata": {},
   "source": [
    "# histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f02f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulas from the theory\n",
    "theo_mean_bull = (gbm_par[0][0] - (gbm_par[0][1]**2)/2)*dt\n",
    "theo_mean_bear = (gbm_par[1][0] - (gbm_par[1][1]**2)/2)*dt\n",
    "\n",
    "theo_variance_bull = (gbm_par[0][1]**2)*dt\n",
    "theo_variance_bear = (gbm_par[1][1]**2)*dt\n",
    "\n",
    "theo_std_bull = np.sqrt(theo_variance_bull)\n",
    "theo_std_bear = np.sqrt(theo_variance_bear)\n",
    "\n",
    "# print values\n",
    "print(f\"mean bull = {theo_mean_bull}\")\n",
    "print(f\"mean centroid 0 = {np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index]}\")\n",
    "\n",
    "print(f\"\\nvariance bull = {theo_variance_bull}\")\n",
    "print(f\"variance centroid 0 = {np.var(wkmeans.cluster_centers_, axis=1)[off_regime_index]}\")\n",
    "\n",
    "\n",
    "print(f\"\\nmean bear = {theo_mean_bear}\")\n",
    "print(f\"mean centroid 1 = {np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index]}\")\n",
    "\n",
    "print(f\"\\nvariance bear = {theo_variance_bear}\")\n",
    "print(f\"variance centroid 1 = {np.var(wkmeans.cluster_centers_, axis=1)[on_regime_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83ae50",
   "metadata": {},
   "source": [
    "## histogram of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2617e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.mean(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b') \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_mean_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_mean_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.mean(wkmeans.cluster_centers_, axis=1)[off_regime_index], color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=np.mean(wkmeans.cluster_centers_, axis=1)[on_regime_index], color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Distribution')\n",
    "plt.xlabel('μ')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0c1fe",
   "metadata": {},
   "source": [
    "### histogram of the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.std(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b')  \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_std_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_std_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.std(wkmeans.cluster_centers_, axis=1)[off_regime_index], color='green', linestyle='--', label='centroid 0')\n",
    "plt.axvline(x=np.std(wkmeans.cluster_centers_, axis=1)[on_regime_index], color='red', linestyle='--', label='centroid 1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(f'$\\sigma$')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda83df",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b915c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, p, max_iter, tol, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs): \n",
    "        # data preparation\n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(gbm_path(N_prime, price_labels, t)))\n",
    "        X_wasserstein = lift_function(h_1, h_2, log_returns, M)[1]\n",
    "        \n",
    "        # clustering\n",
    "        start = time.time()\n",
    "        \n",
    "        wkmeans = WassersteinKMeans(p=p, max_iter=max_iter, tol=tol)\n",
    "        wkmeans.fit(X_wasserstein)\n",
    "        \n",
    "        # off-regime-> cluster with a higher number of elements\n",
    "        off_regime_index = 0 \n",
    "        # on-regime-> cluster with a lower number of elements\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (wkmeans.labels_ == 0).sum() < (wkmeans.labels_ == 1).sum():\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "\n",
    "            \n",
    "        # counter   \n",
    "        r_counter = opt_counter(wkmeans, N_prime, M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clustering validation parameters\n",
    "P = 1\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "n_runs = 50\n",
    "\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, P, max_iter, tol, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e11592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(f'numerical_results/{P}_W_means_h_{h_1}_{h_2}_GBM_n_{n_runs}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2d985",
   "metadata": {},
   "source": [
    "# Comparison: validation method  via MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples from a cluster\n",
    "n_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mmd_squared(x, y, sigma=0.1):\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "\n",
    "    # Compute the MMD terms\n",
    "    K_xx = np.exp(-np.square(x[:, np.newaxis] - x[np.newaxis, :]) / (2 * sigma ** 2))\n",
    "    K_xy = np.exp(-np.square(x[:, np.newaxis] - y[np.newaxis, :]) / (2 * sigma ** 2))\n",
    "    K_yy = np.exp(-np.square(y[:, np.newaxis] - y[np.newaxis, :]) / (2 * sigma ** 2))\n",
    "\n",
    "    # Compute the MMD terms using matrix operations\n",
    "    term1 = np.sum(K_xx) / (n * n)\n",
    "    term2 = np.sum(K_xy) / (m * n)\n",
    "    term3 = np.sum(K_yy) / (m * m)\n",
    "\n",
    "    # MMD^2 is the square of the difference\n",
    "    mmd_squared = term1 - 2 * term2 + term3\n",
    "\n",
    "    # Return the square root of the MMD^2\n",
    "    return mmd_squared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46be41",
   "metadata": {},
   "source": [
    "# between-cluster similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_cluster_sim(n, matrix, kmeans):\n",
    "    # matrix is the lift_matrix\n",
    "    mmd_bet_array = np.zeros(n)\n",
    "\n",
    "    # Number of elements in each cluster\n",
    "    k_off = len(matrix[kmeans.labels_ == off_regime_index])\n",
    "    k_on = len(matrix[kmeans.labels_ == on_regime_index])\n",
    "\n",
    "    # Samples from cluster OFF\n",
    "    np.random.seed(42)\n",
    "    random_indexes_off = np.random.randint(0, k_off, size=n)\n",
    "    subs_off = matrix[kmeans.labels_ == off_regime_index][random_indexes_off]\n",
    "\n",
    "    # Samples from cluster ON\n",
    "    np.random.seed(43)  # You can keep the seed consistent or change it if desired\n",
    "    random_indexes_on = np.random.randint(0, k_on, size=n)\n",
    "    subs_on = matrix[kmeans.labels_ == on_regime_index][random_indexes_on]\n",
    "\n",
    "    # Calculate MMD for each sample pair\n",
    "    for i, (x, y) in enumerate(zip(subs_off, subs_on)):\n",
    "        mmd_bet_array[i] = compute_mmd_squared(x, y)\n",
    "        \n",
    "    return mmd_bet_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_bet_array_1_s = between_cluster_sim(n_samples, lift_matrix, wkmeans)\n",
    "mmd_bet_array_1 = np.sqrt(mmd_bet_array_1_s)\n",
    "print(f\"between SIM 1 squared= {np.median(mmd_bet_array_1_s)}\")\n",
    "print(f\"between SIM 1= {np.median(mmd_bet_array_1)}\")\n",
    "plt.hist(mmd_bet_array_1, bins=int(np.sqrt(len(mmd_bet_array_1))), density=True, alpha=0.6)\n",
    "plt.title(\"(normalized) Histogram of BETWEEN-cluster MMD approximation\")\n",
    "plt.xlabel(\"$MMD_{b}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_bet_array_2_s = between_cluster_sim(n_samples, lift_matrix, wkmeans)\n",
    "mmd_bet_array_2 = np.sqrt(mmd_bet_array_2_s)\n",
    "# print scores\n",
    "print(f\"between SIM bad squared = {np.median(mmd_bet_array_1_s)}\")\n",
    "print(f\"between SIM good squared= {np.median(mmd_bet_array_2_s)}\")\n",
    "print(f\"between SIM bad = {np.median(mmd_bet_array_1)}\")\n",
    "print(f\"between SIM good = {np.median(mmd_bet_array_2)}\")\n",
    "# distributions\n",
    "plt.hist(mmd_bet_array_1, bins=int(np.sqrt(len(mmd_bet_array_1))), density=True, alpha=0.6, label='bad clustering')\n",
    "plt.hist(mmd_bet_array_2, bins=int(np.sqrt(len(mmd_bet_array_2))), density=True, alpha=0.6, label='good clustering')\n",
    "\n",
    "\n",
    "plt.title(\"(normalized) Histogram of BETWEEN-cluster MMD approximation\")\n",
    "plt.xlabel(\"$MMD_{b}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b119af",
   "metadata": {},
   "source": [
    "# inter-cluster similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc002835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_cluster_sim(n, matrix, kmeans, c):\n",
    "    k = len(matrix[kmeans.labels_ == c])\n",
    "    # number of pairs from a cluster\n",
    "    mmd_array = np.zeros(n)\n",
    "    np.random.seed(42)\n",
    "    # random indexes\n",
    "    random_indexes = np.random.randint(0, k, size=int(n*2))\n",
    "\n",
    "    # samples 0\n",
    "    subs_0 = matrix[kmeans.labels_ == c][random_indexes[::2]]\n",
    "\n",
    "    # samples 1\n",
    "    subs_1 = matrix[kmeans.labels_ == c][random_indexes[1::2]]\n",
    "\n",
    "    # calculate MMD for each sample pair\n",
    "    for i, (x, y) in enumerate(zip(subs_0, subs_1)):\n",
    "        mmd_array[i] = compute_mmd_squared(x, y)\n",
    "\n",
    "    return mmd_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49015a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_inter_array_off_1_s = inter_cluster_sim(n_samples, lift_matrix, wkmeans, off_regime_index)\n",
    "mmd_inter_array_on_1_s = inter_cluster_sim(n_samples, lift_matrix, wkmeans, on_regime_index)\n",
    "# sqrt\n",
    "mmd_inter_array_off_1 = np.sqrt(mmd_inter_array_off_1_s)\n",
    "mmd_inter_array_on_1 = np.sqrt(mmd_inter_array_on_1_s)\n",
    "# print scores\n",
    "print(f\"int_sim_off squared = {np.median(mmd_inter_array_off_1_s)} \\nint_sim_on squared= {np.median(mmd_inter_array_on_1_s)}\")\n",
    "print(f\"int_sim_off = {np.median(mmd_inter_array_off_1)} \\nint_sim_on = {np.median(mmd_inter_array_on_1)}\")\n",
    "# print distributions\n",
    "plt.hist(mmd_inter_array_off_1, bins=int(np.sqrt(n_samples)), density=True, alpha=0.6, label='off regime')\n",
    "plt.hist(mmd_inter_array_on_1, bins=int(np.sqrt(n_samples)), density=True, alpha=0.6, label='on regime')\n",
    "\n",
    "plt.title(\"(normalized) Histogram of INTER-cluster MMD approximation\")\n",
    "plt.xlabel(\"$MMD_{b}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_inter_array_off_2_s = inter_cluster_sim(n_samples, lift_matrix, wkmeans, off_regime_index)\n",
    "mmd_inter_array_on_2_s = inter_cluster_sim(n_samples, lift_matrix, wkmeans, on_regime_index)\n",
    "# sqrt\n",
    "mmd_inter_array_off_2 = np.sqrt(mmd_inter_array_off_2_s)\n",
    "mmd_inter_array_on_2 = np.sqrt(mmd_inter_array_on_2_s)\n",
    "# print scores\n",
    "print(f\"int_sim_off squared = {np.median(mmd_inter_array_off_2_s)} \\nint_sim_on squared= {np.median(mmd_inter_array_on_2_s)}\")\n",
    "print(f\"int_sim_off = {np.median(mmd_inter_array_off_2)} \\nint_sim_on = {np.median(mmd_inter_array_on_2)}\")\n",
    "\n",
    "\n",
    "plt.hist(mmd_inter_array_off_2, bins=int(np.sqrt(n_samples)), density=True, alpha=0.6, label='off regime')\n",
    "plt.hist(mmd_inter_array_on_2, bins=int(np.sqrt(n_samples)), density=True, alpha=0.6, label='on regime')\n",
    "plt.title(\"(normalized) Histogram of INTER-cluster MMD approximation\")\n",
    "plt.xlabel(\"$MMD_{b}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653548f",
   "metadata": {},
   "source": [
    "#  price path and log returns clustering\n",
    "it may be a bit ambiguous... the paper is not so clear about the clustering on the prices data. This problem is clearly related to the visualization of different regimes on the price path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e7575",
   "metadata": {},
   "source": [
    "# log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two important functions to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69fc77",
   "metadata": {},
   "source": [
    "# price path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a20d2",
   "metadata": {},
   "source": [
    "## 1st method\n",
    "I chose this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355307da",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcab48",
   "metadata": {},
   "source": [
    "## 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(s_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(prices)):\n",
    "    \n",
    "    if i == (len(prices) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
