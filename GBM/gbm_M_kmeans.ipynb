{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a57b97",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c067fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "# GBM parameters\n",
    "gbm_par = np.array(\n",
    "    [[0.02, 0.2], #mu,sigma bull-regime\n",
    "    [-0.02, 0.3]]) #mu,sigma bear-regime\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ee3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbm(S0, mu, sigma, n, dt):\n",
    "    \"\"\"\n",
    "    Simulates a Geometric Brownian Motion (GBM).\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift coefficient\n",
    "    sigma (float): Volatility coefficient\n",
    "    T (float): Time horizon\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    t = np.arange(1, n) * dt\n",
    "    W = np.random.standard_normal(size=n-1) \n",
    "    W = np.cumsum(W) * np.sqrt(dt) # cumulative sum to simulate the Brownian motion\n",
    "    X = (mu - 0.5 * sigma**2) * t + sigma * W\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    S[1:] = S0 * np.exp(X)\n",
    "    return S\n",
    "\n",
    "def gbm_path(N_prime, C, t):\n",
    "    \n",
    "#     np.random.seed(17)\n",
    "    '''\n",
    "    It simulates the entire path of a GBM with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]), dt)\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]), dt)\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 15\n",
    "np.random.seed(seed_path)\n",
    "\n",
    "# relevant time series\n",
    "prices = gbm_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Geometric Brownian Motion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dcbbf",
   "metadata": {},
   "source": [
    "## MK-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKMeans:\n",
    "    \n",
    "    def __init__(self, max_iter, tol, n_clusters=2, random_state=None):\n",
    "        \n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Initialize cluster centers\n",
    "        indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.cluster_centers_ = X[indices]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            # Compute distances and assign clusters\n",
    "            distances = pairwise_distances(X, self.cluster_centers_, metric='euclidean')\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Compute new cluster centers\n",
    "            new_centers = np.array([np.mean(X[labels == j] ,axis=0) for j in range(self.n_clusters)])\n",
    "            \n",
    "            # Check for convergence\n",
    "            loss = 0\n",
    "            for j in range(self.n_clusters):\n",
    "                loss = loss + np.linalg.norm(self.cluster_centers_[j] - new_centers[j])\n",
    "                \n",
    "            if loss < self.tol:\n",
    "                break\n",
    "\n",
    "            self.cluster_centers_ = new_centers\n",
    "\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = pairwise_distances(X, self.cluster_centers_, metric=euclidean_distance)\n",
    "        return np.argmin(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9143596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costruction of a suitable dataset\n",
    "\n",
    "# from each empiracal cdf we take the firsts q moments (a vector of dim. q for each empirical cdf)\n",
    "q = 4\n",
    "\n",
    "# Function to compute the k-th raw moment along a specified axis\n",
    "def raw_moment_nd(values, k, axis=None):\n",
    "    return np.mean(values**k, axis=axis)\n",
    "\n",
    "\n",
    "# compute raw moments along the specified axis (axis=None computes the raw moments over the entire array)\n",
    "X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "# print the standardized data\n",
    "print(np.mean(standardized_X_moments, axis=0))\n",
    "print(np.std(standardized_X_moments, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the  MK-means\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "seed_clustering = 1\n",
    "\n",
    "mkmeans = MKMeans(max_iter=max_iter, tol=tol, random_state=seed_clustering)\n",
    "mkmeans.fit(standardized_X_moments)\n",
    "\n",
    "# centroids in the real space\n",
    "centroids = scaler.inverse_transform(mkmeans.cluster_centers_) \n",
    "\n",
    "# off-regime-> higher number of elements\n",
    "off_regime_index = 0 \n",
    "# on-regime-> lower number of elements\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (mkmeans.labels_ == 0).sum() < (mkmeans.labels_ == 1).sum():\n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "\n",
    "# scatter plot of centroids\n",
    "\n",
    "plt.scatter(np.sqrt(centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2),\n",
    "            centroids[off_regime_index][0],\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "plt.scatter(np.sqrt(centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2),\n",
    "            centroids[on_regime_index][0],\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'M k-means with p={q}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{q}_M_means_{seed_clustering}_h_{h_1}_{h_2}_GBM_{seed_path}_ite_{max_iter}_tol_{tol}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_and_kurtosis(M):\n",
    "    \"\"\"\n",
    "    Calculate skewness and excess kurtosis using raw moments.\n",
    "    \n",
    "    Parameters:\n",
    "    M1: First raw moment (mean)\n",
    "    M2: Second raw moment (variance-related)\n",
    "    M3: Third raw moment\n",
    "    M4: Fourth raw moment\n",
    "    \n",
    "    Returns:\n",
    "    skewness, excess kurtosis\n",
    "    \"\"\"\n",
    "    M1 = M[0]\n",
    "    M2 = M[1]\n",
    "    M3 = M[2]\n",
    "    M4 = M[3]\n",
    "    \n",
    "    # Calculate variance (second central moment, which is just variance)\n",
    "    mu2 = M2 - M1**2\n",
    "\n",
    "    # Calculate third central moment\n",
    "    mu3 = M3 - 3 * M1 * M2 + 2 * M1**3\n",
    "\n",
    "    # Calculate fourth central moment\n",
    "    mu4 = M4 - 4 * M1 * M3 + 6 * M1**2 * M2 - 3 * M1**4\n",
    "\n",
    "    # Calculate skewness\n",
    "    skewness = mu3 / mu2**(3/2)\n",
    "\n",
    "    # Calculate excess kurtosis (subtract 3 from kurtosis)\n",
    "    excess_kurtosis = (mu4 / mu2**2) - 3\n",
    "\n",
    "    return skewness, excess_kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: RUN THIS IF q IS AT LEAST 4\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "point_size = 4\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[mkmeans.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.3, s=point_size)\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[mkmeans.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=0.4, s=point_size)\n",
    "# scatter plot of centroids\n",
    "skewness_0, excess_kurtosis_0 = skewness_and_kurtosis(centroids[off_regime_index])\n",
    "plt.scatter(skewness_0,\n",
    "            excess_kurtosis_0,\n",
    "            color='blue', marker='x', label='centroid 0')\n",
    "\n",
    "skewness_1, excess_kurtosis_1 = skewness_and_kurtosis(centroids[on_regime_index])\n",
    "plt.scatter(skewness_1,\n",
    "            excess_kurtosis_1,\n",
    "            color='red', marker='x', label='centroid 1')\n",
    "\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'M k-means p={q}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{q}_M_means_{seed_clustering}_h_{h_1}_{h_2}_GBM_{seed_path}_ite_{max_iter}_tol_{tol}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238cc6d",
   "metadata": {},
   "source": [
    "## Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b548a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d751eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(mkmeans, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "dec = 2\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, dec)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, dec)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, dec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96284288",
   "metadata": {},
   "source": [
    "## log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e956ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two important functions to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "\n",
    "\n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36aa884",
   "metadata": {},
   "source": [
    "## price path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf8bdb",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, q, max_iter, tol, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs): \n",
    "        \n",
    "        # data preparation\n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(gbm_path(N_prime, price_labels, t)))\n",
    "        # start timing\n",
    "        start = time.time()\n",
    "        lift_matrix = lift_function(h_1, h_2, log_returns, M)[0]\n",
    "        \n",
    "        X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "        # initialize the StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        # fit and transform the data\n",
    "        standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "        # clustering\n",
    "        mkmeans = MKMeans(max_iter=max_iter, tol=tol)\n",
    "        mkmeans.fit(standardized_X_moments)\n",
    "\n",
    "        # centroids in the real space\n",
    "        centroids = scaler.inverse_transform(mkmeans.cluster_centers_) \n",
    "\n",
    "        # off-regime-> higher number of elements\n",
    "        off_regime_index = 0 \n",
    "        # on-regime-> lower number of elements\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (mkmeans.labels_ == 0).sum() < (mkmeans.labels_ == 1).sum():\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "            \n",
    "        # counter    \n",
    "        r_counter = opt_counter(mkmeans, len(log_returns), M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Q = 4\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "n_runs = 50\n",
    "\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, Q, max_iter, tol, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35401002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(f'numerical_results/{Q}_M_means_h_{h_1}_{h_2}_GBM_n_{n_runs}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74095782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11121e8",
   "metadata": {},
   "source": [
    "# dependences by the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: run again if you change something in the section Data preparation !!!\n",
    "\n",
    "def mk_means_function(X, max_iter, tol, random_seed):\n",
    "\n",
    "    # Fit the  MK-means\n",
    "    mkmeans = MKMeans(max_iter=max_iter, tol=tol, random_state=random_seed)\n",
    "    mkmeans.fit(X)\n",
    "\n",
    "    # off-regime-> higher number of elements\n",
    "    off_regime_index = 0 \n",
    "    # on-regime-> lower number of elements\n",
    "    on_regime_index = 1 \n",
    "    # check regime\n",
    "    if (mkmeans.labels_ == 0).sum() < (mkmeans.labels_ == 1).sum():\n",
    "        off_regime_index = 1\n",
    "        on_regime_index = 0\n",
    "        \n",
    "        \n",
    "    r_counter, s_counter = opt_counter(mkmeans, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "    # regime-off accuracy score (ROFS)\n",
    "    ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "    # regime-off accuracy score (ROFS)\n",
    "    RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "    # total accuracy (TA)\n",
    "    TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "    \n",
    "    return ROFS, RONS, TA\n",
    "\n",
    "\n",
    "def convert_seconds(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    remaining_seconds = seconds % 60\n",
    "    return f\"{minutes} min {int(remaining_seconds)} seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc99080",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 50\n",
    "\n",
    "# clustering parameters\n",
    "Q = 4\n",
    "max_iter = 600\n",
    "tol = 1e-8\n",
    "\n",
    "# compute raw moments along the specified axis (axis=None computes the raw moments over the entire array)\n",
    "X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, Q+1)]).T\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "# stability analysis\n",
    "rofs = np.zeros(n_trials)\n",
    "rons = np.zeros(n_trials)\n",
    "ta = np.zeros(n_trials)\n",
    "iteration_times = np.zeros(n_trials)\n",
    "\n",
    "start_time_tot = time.time()\n",
    "for i in range(n_trials):\n",
    "    # start\n",
    "    start_time = time.time()\n",
    "    # real computation\n",
    "    rofs[i], rons[i], ta[i] = mk_means_function(standardized_X_moments, max_iter, tol, i+1)\n",
    "    # end\n",
    "    end_time = time.time()\n",
    "    # save data\n",
    "    iteration_times[i] = end_time - start_time\n",
    "end_time_tot = time.time()\n",
    "\n",
    "input_seconds = float(end_time_tot - start_time_tot)\n",
    "print(f'time to complete all the iterations = {convert_seconds(input_seconds)}')\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(f'numerical_results_stability/{Q}_M_means_h_{h_1}_{h_2}_GBM_{seed_path}_n_{n_trials}_ite_{max_iter}_tol_{tol}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results_stability/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "n_trials = len(ta)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f3bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_bins = int(np.sqrt(n_trials))\n",
    "# nn_bins = n_trials\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(rofs, bins=nn_bins, density=True)\n",
    "plt.xlabel('ROFS')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.hist(rons, bins=nn_bins, density=True)\n",
    "plt.xlabel('RONS')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.hist(ta, bins=nn_bins, density=True)\n",
    "plt.xlabel('TA')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.hist(iteration_times, bins=nn_bins, density=True)\n",
    "plt.xlabel('RUN TIME (seconds)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc2d268",
   "metadata": {},
   "source": [
    "# (normalized) histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dafa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulas from the theory\n",
    "theo_mean_bull = (gbm_par[0][0] - (gbm_par[0][1]**2)/2)*dt\n",
    "theo_mean_bear = (gbm_par[1][0] - (gbm_par[1][1]**2)/2)*dt\n",
    "\n",
    "theo_variance_bull = (gbm_par[0][1]**2)*dt\n",
    "theo_variance_bear = (gbm_par[1][1]**2)*dt\n",
    "\n",
    "theo_std_bull = np.sqrt(theo_variance_bull)\n",
    "theo_std_bear = np.sqrt(theo_variance_bear)\n",
    "\n",
    "# print values\n",
    "print(f\"mean bull = {theo_mean_bull}\")\n",
    "print(f\"mean centroid 0 = {centroids[off_regime_index][0]}\")\n",
    "\n",
    "print(f\"\\nvariance bull = {theo_variance_bull}\")\n",
    "print(f\"variance centroid 0 = {centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2}\")\n",
    "\n",
    "\n",
    "print(f\"\\nmean bear = {theo_mean_bear}\")\n",
    "print(f\"mean centroid 1 = {centroids[on_regime_index][0]}\")\n",
    "\n",
    "print(f\"\\nvariance bear = {theo_variance_bear}\")\n",
    "print(f\"variance centroid 1 = {centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c890b61",
   "metadata": {},
   "source": [
    "### (normalized) histogram of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.mean(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b', density=True) \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_mean_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_mean_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=centroids[off_regime_index][0], color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=centroids[on_regime_index][0], color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "# plt.title('Distribution')\n",
    "plt.xlabel('Î¼')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a924e",
   "metadata": {},
   "source": [
    "### (normalized) histogram of the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "data = np.std(lift_matrix, axis=1)\n",
    "n_bins = int(np.sqrt(M))\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=n_bins, alpha=0.6, color='b', density=True)  \n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(x=theo_std_bull, color='green', linestyle='-', label='theo_bull')\n",
    "plt.axvline(x=theo_std_bear, color='red', linestyle='-', label='theo_bear')\n",
    "plt.axvline(x=np.sqrt(centroids[off_regime_index][1] - (centroids[off_regime_index][0])**2), color='green', linestyle='--', label='centroid_0')\n",
    "plt.axvline(x=np.sqrt(centroids[on_regime_index][1] - (centroids[on_regime_index][0])**2), color='red', linestyle='--', label='centroid_1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(f'$\\sigma$')\n",
    "# plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
