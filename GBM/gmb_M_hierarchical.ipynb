{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0bbaef",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2291561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "# time horizon in years\n",
    "T = 20  \n",
    "\n",
    "# number of time steps\n",
    "N = int(T * 252 * 7)  \n",
    "\n",
    "# change remige's lenght\n",
    "l_regime = int(0.5  * 252 * 7)\n",
    "\n",
    "# time interval\n",
    "dt = T / N\n",
    "\n",
    "# GBM parameters\n",
    "gbm_par = np.array(\n",
    "    [[0.02, 0.2], #mu,sigma bull-regime\n",
    "    [-0.02, 0.3]]) #mu,sigma bear-regime\n",
    "\n",
    "# array of all the timesteps\n",
    "timestep = np.linspace(0, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23189208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_par(h_1, h_2):\n",
    "    '''\n",
    "    Given the hyper parameters h_1 and h_2 it returns the number of sub-sequences M and the effective number of log-returns that\n",
    "    are involved in the analysis N_prime.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check the number of possible sub sequences M\n",
    "    i = 0\n",
    "    # N - 2 (-1:from price to log-return and -1:becuase the last index is lenght of the array -1)\n",
    "    while ((h_1 - h_2) * i + h_1) <= (N-2):\n",
    "        i = i + 1\n",
    "\n",
    "    # IMPORTANT parameters\n",
    "    M = i \n",
    "    N_prime = (h_1 - h_2) * (M-1) + h_1 + 1\n",
    "    \n",
    "    return N_prime, M\n",
    "\n",
    "h_1 = 35\n",
    "h_2 = 28\n",
    "\n",
    "N_prime, M = data_par(h_1, h_2)\n",
    "t = timestep[: N_prime + 1]\n",
    "\n",
    "print(f\"price values not included in the analysis = {len(timestep) - len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a481f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regimes(N_prime):\n",
    "    '''\n",
    "    It generates randomly 10 different time interval of the same same lenght.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    A = np.arange(0, N_prime+1)\n",
    "\n",
    "    # Parametri delle sottosequenze\n",
    "    num_subsequences = 10\n",
    "    subseq_length = l_regime \n",
    "\n",
    "    # Set per memorizzare gli indici di partenza usati\n",
    "    used_indices = set()\n",
    "\n",
    "    # Funzione per generare un indice di partenza valido\n",
    "    def generate_start_index(random_state=17):\n",
    "        np.random.seed(random_state)\n",
    "        while True:\n",
    "            # Genera un indice di partenza casuale\n",
    "            start_index = np.random.randint(0, len(A) - subseq_length - 1)\n",
    "            # Controlla se l'indice di partenza e l'indice finale (con buffer di 1) sono validi\n",
    "            if all((start_index + i) not in used_indices for i in range(subseq_length + 1)):\n",
    "                for i in range(subseq_length + 1):\n",
    "                    used_indices.add(start_index + i)\n",
    "                return start_index\n",
    "\n",
    "    # Generazione delle sottosequenze random non sovrapposte con almeno un elemento di distanza\n",
    "    subsequences = []\n",
    "    for _ in range(num_subsequences):\n",
    "        start_index = generate_start_index()\n",
    "        subsequences.append(A[start_index:start_index + subseq_length])\n",
    "\n",
    "    subsequences = np.sort(np.array(subsequences), axis=0)\n",
    "    \n",
    "    # label for the log-returns\n",
    "    B = np.zeros(N_prime)\n",
    "    for sub in subsequences:\n",
    "        B[sub[0]: sub[-1]] = 1    \n",
    "    B = B.astype(int)\n",
    "\n",
    "    # label for prices\n",
    "    C = np.zeros(N_prime+1)\n",
    "    for sub in subsequences:\n",
    "        C[sub] = 1    \n",
    "    C = C.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return subsequences, B, C\n",
    "\n",
    "subsequences, theo_labels, labels_prices = generate_regimes(N_prime)\n",
    "\n",
    "# plot of the regimes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(10):\n",
    "    plt.axvspan(timestep[subsequences[i][0]], timestep[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbm(S0, mu, sigma, n, dt):\n",
    "    \"\"\"\n",
    "    Simulates a Geometric Brownian Motion (GBM).\n",
    "\n",
    "    Parameters:\n",
    "    S0 (float): Initial stock price\n",
    "    mu (float): Drift coefficient\n",
    "    sigma (float): Volatility coefficient\n",
    "    T (float): Time horizon\n",
    "    n (int): Number of time steps\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Simulated stock prices\n",
    "\n",
    "    \"\"\"\n",
    "    t = np.arange(1, n) * dt\n",
    "    W = np.random.standard_normal(size=n-1) \n",
    "    W = np.cumsum(W) * np.sqrt(dt) # cumulative sum to simulate the Brownian motion\n",
    "    X = (mu - 0.5 * sigma**2) * t + sigma * W\n",
    "    S = np.zeros(n)\n",
    "    S[0] = S0\n",
    "    S[1:] = S0 * np.exp(X)\n",
    "    return S\n",
    "\n",
    "def gbm_path(N_prime, C, t):\n",
    "    \n",
    "    '''\n",
    "    It simulates the entire path of a GBM with regimes switch.\n",
    "    \n",
    "    '''\n",
    "    # array of prices\n",
    "    s = np.zeros(N_prime + 1)\n",
    "    # initial stock price\n",
    "    s[0] = 1\n",
    "    s_0 = s[0]\n",
    "    start_index = 0\n",
    "    stop_index = 1\n",
    "\n",
    "    for k in range(1, N_prime+1):\n",
    "        if k == N_prime:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]), dt)\n",
    "\n",
    "        elif C[k] == C[k+1]:\n",
    "            stop_index = k+1\n",
    "\n",
    "        else:\n",
    "            s[start_index : stop_index + 1] = gbm(s_0, gbm_par[C[k]][0], gbm_par[C[k]][1], len(t[start_index : stop_index + 1]), dt)\n",
    "            #updates\n",
    "            start_index = k\n",
    "            s_0 = s[k]\n",
    "            stop_index = k + 1\n",
    "            \n",
    "    return s\n",
    "\n",
    "# to ensure reproducibility\n",
    "seed_path = 15\n",
    "np.random.seed(seed_path)\n",
    "\n",
    "# relevant time series\n",
    "prices = gbm_path(N_prime, labels_prices, t)  \n",
    "log_returns = np.diff(np.log(prices))\n",
    "\n",
    "print(f'mean_path = {np.mean(prices)} \\nstd_path = {np.std(prices)}')\n",
    "\n",
    "# plot price path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t,prices)\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)\n",
    "        \n",
    "    \n",
    "#plt.title(\"Geometric Brownian Motion Simulation\")\n",
    "plt.xlabel(\"time (years)\")\n",
    "plt.ylabel(\"stock price\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7827f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_function(h_1, h_2, log_returns, M):\n",
    "    '''\n",
    "    It returns a matrix (and the sorted version) in which the rows are the subsequences.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # creation of the sub-sequences\n",
    "    lift_matrix = np.ndarray((M, h_1 + 1))\n",
    "\n",
    "    for j in range(0, M):\n",
    "        lift_matrix[j] = log_returns[(h_1 - h_2) * j : (h_1 - h_2) * j + h_1 + 1]\n",
    "\n",
    "    sorted_lift_matrix = np.sort(lift_matrix)\n",
    "    return lift_matrix, sorted_lift_matrix\n",
    "\n",
    "lift_matrix, sorted_lift_matrix = lift_function(h_1, h_2, log_returns, M)\n",
    "print(f'number of sub sequences = {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305ae76",
   "metadata": {},
   "source": [
    "##  M Hierarchical (agglomerative) clustering \n",
    "kinds of linkage:\n",
    "\n",
    "‘ward’ minimizes the variance of the clusters being merged.\n",
    "\n",
    "‘average’ uses the average of the distances of each observation of the two sets.\n",
    "\n",
    "‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.\n",
    "\n",
    "‘single’ uses the minimum of the distances between all observations of the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7543be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each empiracal cdf we take the firsts q moments (a vector of dim. q for each empirical cdf)\n",
    "q = 4\n",
    "\n",
    "# Function to compute the k-th raw moment along a specified axis\n",
    "def raw_moment_nd(values, k, axis=None):\n",
    "    return np.mean(values**k, axis=axis)\n",
    "\n",
    "\n",
    "# compute raw moments along the specified axis (axis=None computes the raw moments over the entire array)\n",
    "X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "# print the standardized data\n",
    "print(np.mean(standardized_X_moments, axis=0))\n",
    "print(np.std(standardized_X_moments, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e86694",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = 'ward'\n",
    "\n",
    "clustering = AgglomerativeClustering(linkage=linkage).fit(standardized_X_moments)\n",
    "\n",
    "# off-regime-> higher number of elememnts in the cluster\n",
    "off_regime_index = 0 \n",
    "# on-regime-> lower number of elememnts in the cluster\n",
    "on_regime_index = 1 \n",
    "# check regime\n",
    "if (clustering.labels_ == 1).sum() > (clustering.labels_ == 0).sum():\n",
    "    \n",
    "    off_regime_index = 1\n",
    "    on_regime_index = 0\n",
    "\n",
    "\n",
    "# scatter plot of empirical cdf\n",
    "point_size = 5\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.5, s=point_size, label='predicted off regime')\n",
    "plt.scatter(\n",
    "    np.std(lift_matrix[clustering.labels_ == on_regime_index], axis=1),\n",
    "    np.mean(lift_matrix[clustering.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=1, s=point_size, label='predicted on regime')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(f'$\\sigma$', size=13)\n",
    "plt.ylabel(f'$\\mu$', size=13)\n",
    "plt.title(f'M-Hierarchical {linkage} linkage with p={q}')\n",
    "plt.legend()\n",
    "# PAY ATTENTION\n",
    "# plt.savefig(f'figures/{q}_M_Hierarchical_{linkage}_h_{h_1}_{h_2}_GBM_{seed_path}_mu_std.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of empirical cdf\n",
    "point_size = 5\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[clustering.labels_ == off_regime_index], axis=1),\n",
    "    marker='.', color='green', alpha=0.5, s=point_size, label='predicted off regime')\n",
    "plt.scatter(\n",
    "    skew(lift_matrix[clustering.labels_ == on_regime_index], axis=1),\n",
    "    kurtosis(lift_matrix[clustering.labels_ == on_regime_index], axis=1),  \n",
    "    marker='.', color='orange', alpha=1, s=point_size, label='predicted on regime')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(f'skew', size=13)\n",
    "plt.ylabel(f'excess kurtosis', size=13)\n",
    "plt.title(f'M-Hierarchical {linkage} linkage with p={q}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'figures/{q}_M_Hierarchical_{linkage}_h_{h_1}_{h_2}_GBM_{seed_path}_kurt_skew.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94b7e2",
   "metadata": {},
   "source": [
    "## Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_counter(kmeans, n, M, h_1, h_2):\n",
    "\n",
    "\n",
    "    # Define the time indices for the sliding window\n",
    "    time_indices = np.arange(n)[:, None] - (h_1 - h_2) * np.arange(M)[None, :]\n",
    "\n",
    "    # Mask invalid indices\n",
    "    valid_mask = (time_indices >= 0) & (time_indices <= h_1)\n",
    "\n",
    "    # Use the valid_mask to filter time indices\n",
    "    filtered_time_indices = time_indices * valid_mask\n",
    "\n",
    "    # Create the labels array, repeated across all k for efficient processing\n",
    "    labels_repeated = np.tile(kmeans.labels_, (n, 1))\n",
    "\n",
    "    # Use the valid mask to apply the labels where indices are valid\n",
    "    filtered_labels = np.where(valid_mask, labels_repeated, -1)\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    r_counter_0 = np.sum(filtered_labels == 0, axis=1)\n",
    "    r_counter_1 = np.sum(filtered_labels == 1, axis=1)\n",
    "\n",
    "    # Combine the counts into a single array\n",
    "    r_counter = np.stack((r_counter_0, r_counter_1), axis=1)\n",
    "    \n",
    "    # Initialize s_counter with the same shape as r_counter\n",
    "    s_counter = np.zeros((n+1, 2))\n",
    "\n",
    "    # Handle the first element\n",
    "    s_counter[0] = r_counter[0]\n",
    "\n",
    "    # Handle the last element\n",
    "    s_counter[-1] = r_counter[-1]\n",
    "\n",
    "    # For all other elements, sum the current and previous elements\n",
    "    s_counter[1:-1] = r_counter[:-1] + r_counter[1:]\n",
    "\n",
    "    \n",
    "    return r_counter, s_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c00eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_counter, s_counter = opt_counter(clustering, len(log_returns), M, h_1, h_2)\n",
    "\n",
    "dec = 4\n",
    "# regime-off accuracy score (ROFS)\n",
    "ROFS = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "print(f'ROFS = {round(ROFS, dec)}')\n",
    "\n",
    "# regime-off accuracy score (ROFS)\n",
    "RONS = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "print(f'RONS = {round(RONS, dec)}')\n",
    "\n",
    "# total accuracy (TA)\n",
    "TA = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "print(f'TA = {round(TA, dec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2195cb7",
   "metadata": {},
   "source": [
    "## log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c18412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two important functions to allow a correct way to plot data\n",
    "def compare_columns(A):\n",
    "    \n",
    "    B = np.where(A[:, 0] > A[:, 1], 0, np.where(A[:, 0] < A[:, 1], 1, 2))\n",
    "    \n",
    "    if off_regime_index == 1:\n",
    "        B = np.where(B == 0, 1, np.where(B == 1, 0, B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 0\n",
    "end_j = 0\n",
    "m_size = 1\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 1\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], log_returns[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 1\n",
    "        end_j = i + 1\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('log-returns')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8616c",
   "metadata": {},
   "source": [
    "## price path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compare_columns(r_counter)\n",
    "color = ['green', 'red', 'blue']\n",
    "start_j = 1\n",
    "end_j = 1\n",
    "m_size = 0.5\n",
    "\n",
    "if not 2 in b:\n",
    "    print('no ambiguos clustering')\n",
    "else:\n",
    "    print('ambiguos clustering')\n",
    "    \n",
    "\n",
    "for i in range(0, len(log_returns)):\n",
    "    \n",
    "    if i == (len(log_returns) - 1):\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "    \n",
    "    elif b[i] == b[i+1]:\n",
    "        end_j = i + 2\n",
    "        \n",
    "    else:\n",
    "        plt.plot(t[start_j: end_j + 1], prices[start_j: end_j + 1], \n",
    "                 color=color[b[i]], marker='.', linewidth=m_size, markersize=m_size)\n",
    "        start_j = i + 2\n",
    "        end_j = i + 2\n",
    "        \n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3, label='regime switch')\n",
    "        \n",
    "    else:\n",
    "        plt.axvspan(t[subsequences[i][0]], t[subsequences[i][-1]], color='red', alpha=0.3)        \n",
    "      \n",
    "        \n",
    "plt.legend()  \n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time (years)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30e1b3",
   "metadata": {},
   "source": [
    "# CLUSTERING VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_validation(h_1, h_2, q, linkage, n_runs):\n",
    "    \n",
    "    rofs = np.zeros(n_runs)\n",
    "    rons = np.zeros(n_runs)\n",
    "    ta = np.zeros(n_runs)\n",
    "    iteration_times = np.zeros(n_runs)\n",
    "    \n",
    "    N_prime, M = data_par(h_1, h_2)\n",
    "    t = timestep[: N_prime + 1]\n",
    "    subs, theo_labels, price_labels = generate_regimes(N_prime)\n",
    "    \n",
    "    for j in range(n_runs): \n",
    "        \n",
    "        # data preparation\n",
    "        np.random.seed(j)\n",
    "        log_returns = np.diff(np.log(gbm_path(N_prime, price_labels, t)))\n",
    "        # start timing\n",
    "        start = time.time()\n",
    "        lift_matrix = lift_function(h_1, h_2, log_returns, M)[0]\n",
    "        # \n",
    "        X_moments = np.array([raw_moment_nd(lift_matrix, k, axis=1) for k in range(1, q+1)]).T\n",
    "        # initialize the StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        # fit and transform the data\n",
    "        standardized_X_moments = scaler.fit_transform(X_moments)\n",
    "\n",
    "        ##### clustering\n",
    "        clustering = AgglomerativeClustering(linkage=linkage).fit(standardized_X_moments)\n",
    "\n",
    "        # off-regime\n",
    "        off_regime_index = 0 \n",
    "        # on-regime\n",
    "        on_regime_index = 1 \n",
    "        # check regime\n",
    "        if (clustering.labels_ == 1).sum() > (clustering.labels_ == 0).sum():\n",
    "\n",
    "            off_regime_index = 1\n",
    "            on_regime_index = 0\n",
    "\n",
    "        # counter    \n",
    "        r_counter = opt_counter(clustering, len(log_returns), M, h_1, h_2)[0]\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rofs[j] = np.sum(r_counter[theo_labels == 0].T[off_regime_index])/np.sum(r_counter[theo_labels == 0])\n",
    "\n",
    "        # regime-off accuracy score (ROFS)\n",
    "        rons[j] = np.sum(r_counter[theo_labels == 1].T[on_regime_index])/np.sum(r_counter[theo_labels == 1])\n",
    "\n",
    "        # total accuracy (TA)\n",
    "        ta[j] = (np.sum(r_counter[theo_labels == 0].T[off_regime_index]) + np.sum(r_counter[theo_labels == 1].T[on_regime_index]))/np.sum(r_counter)\n",
    "        \n",
    "        iteration_times[j] = time.time() - start\n",
    "\n",
    "    return rofs, rons, ta, iteration_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a327266",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_runs = 50\n",
    "Q = 4\n",
    "Linkage = 'ward'\n",
    "rofs, rons, ta, iteration_times = clustering_validation(h_1, h_2, Q, Linkage, n_runs)\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7fb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results as txt file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ROFS': rofs,\n",
    "    'RONS': rons,\n",
    "    'TA': ta,\n",
    "    'RUNTIME': iteration_times\n",
    "})\n",
    "\n",
    "df.to_csv(f'numerical_results/{Q}_M_Hierarchical_{Linkage}_h_{h_1}_{h_2}_GBM_n_{n_runs}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad269bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "df = pd.read_csv('numerical_results/')\n",
    "\n",
    "rofs = df['ROFS'].values\n",
    "rons = df['RONS'].values\n",
    "ta = df['TA'].values\n",
    "iteration_times = df['RUNTIME'].values\n",
    "\n",
    "dec = 4\n",
    "print(f\"ROFS = {round(np.mean(rofs), dec)} -+ {round(np.std(rofs), dec)}\")\n",
    "print(f\"RONS = {round(np.mean(rons), dec)} -+ {round(np.std(rons), dec)}\")\n",
    "print(f\"TA = {round(np.mean(ta), dec)} -+ {round(np.std(ta), dec)}\")\n",
    "print(f\"RUN TIME = {round(np.mean(iteration_times), dec)} -+ {round(np.std(iteration_times), dec)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
